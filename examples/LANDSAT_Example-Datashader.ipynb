{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANDSAT and Ensemble Learning Models\n",
    "\n",
    "[Ensemble Learning Models (Elm)](https://github.com/ContinuumIO/elm) was developed for a 2016 NASA SBIR Phase I.  Elm provides large data machine learning tools for satellite imagery and climate data.\n",
    "\n",
    " * Using the AWS S3 LANDSAT data\n",
    " * Using GeoTiff metadata\n",
    " * Feature engineering with `elm.pipeline.Pipeline`\n",
    " * Fitting / predicting with `distributed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from bokeh.models import WMTSTileSource\n",
    "from cartopy import crs as ccrs\n",
    "from collections import defaultdict, OrderedDict\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "from earthio import load_array, load_tif_meta, BandSpec, ElmStore\n",
    "from earthio.landsat_util import landsat_metadata\n",
    "from earthio.s3_landsat_util import SceneDownloader\n",
    "from elm.model_selection.kmeans import kmeans_aic, kmeans_model_averaging\n",
    "from elm.pipeline import Pipeline, steps\n",
    "from holoviews.operation import decimate\n",
    "from holoviews.operation.datashader import aggregate, shade, datashade, dynspread\n",
    "from pyproj import Proj, transform\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "import dill\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import requests\n",
    "import xarray as xr\n",
    "import xarray as xr\n",
    "hv.notebook_extension('bokeh')\n",
    "decimate.max_samples = 1000\n",
    "dynspread.max_px = 20\n",
    "dynspread.threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 LANDSAT downloader\n",
    "See [this example scene from the AWS S3 LANDSAT store](http://landsat-pds.s3.amazonaws.com/L8/015/033/LC80150332013207LGN00/index.html)\n",
    "\n",
    "This example uses `SceneDownloader` to find scenes meeting spatial or cloud cover criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_download = SceneDownloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoTiff options\n",
    "\n",
    "Use `elm.readers.BandSpec` to control:\n",
    "\n",
    " * Resolution\n",
    " * Naming of the bands\n",
    " * Where to find each band's GeoTiff based on file name match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUF_X_SIZE, BUF_Y_SIZE = 600, 600 # Set to 800, 800 for 800 by 800 pix decimation\n",
    "BAND_SPECS = [BandSpec(search_key='name',\n",
    "                       search_value='B{}.TIF'.format(band),\n",
    "                       name='band_{}'.format(band),\n",
    "                       buf_xsize=BUF_X_SIZE,\n",
    "                       buf_ysize=BUF_Y_SIZE) for band in range(1, 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `distributed.Client`\n",
    "\n",
    " * Defaults to creation of local scheduler / workers\n",
    " * Can point to remote scheduler / workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scheduler = os.environ.get('DASK_SCHEDULER')\n",
    "if not scheduler:\n",
    "    client = Client()\n",
    "else:\n",
    "    client = Client(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a cloud free image\n",
    "\n",
    "(For a given LANDSAT row / path and month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_image = s3_download.lowest_cloud_cover_image(row=33, path=15, months=tuple(range(1,13)))\n",
    "clear_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = clear_image.download_url.values[0]\n",
    "download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LANDSAT `sampler` function\n",
    " * Uses `elm.readers.load_array` with `band_specs` argument\n",
    " * Adds MTL file metadata with `elm.readers.landsat_util.landsat_metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampler(download_url, **kwargs):\n",
    "    local_files = s3_download.download_all_bands(download_url)\n",
    "    this_sample_dir = os.path.dirname(local_files[0])\n",
    "    X = load_array(this_sample_dir, band_specs=BAND_SPECS)\n",
    "    X.attrs.update(vars(landsat_metadata([f for f in local_files if f.endswith('.txt')][0])))\n",
    "    y = sample_weight = None\n",
    "    return (X, y, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, _ = sampler(download_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MTL file metadata example\n",
    " * Calculate top of atmosphere (TOA) reflectance for Band 4 (Near Infrared)\n",
    " * Use the reflectance and sun elevation metadata from the MTL file\n",
    " * Use `xarray` plotting with custom color levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mult = X.REFLECTANCE_MULT_BAND_4\n",
    "add = X.REFLECTANCE_ADD_BAND_4\n",
    "theta = X.SUN_ELEVATION * (np.pi / 180.)\n",
    "levels = (-0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.6)\n",
    "band_4_radiance = (X.band_4 * mult + add) / np.sin(theta)\n",
    "band_4_radiance.values[band_4_radiance.values < 0.] = 0.\n",
    "band_4_radiance = hv.Dataset(band_4_radiance)\n",
    "#((X.band_4 * mult + add) / np.sin(theta)).plot.pcolormesh(levels=levels)\n",
    "#matplotlib.pyplot.title('Band 4 (NIR) TOA Reflectance');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_4_radiance.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_4_radiance.dframe().describe(percentiles=[0.05, 0.1, 0.25, 0.5, 0.75, 0.95])[['band_4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Image [ width=800 height=600]\n",
    "#hv.Image(radiance, vdims=['band_4'])\n",
    "hv.Image(band_4_radiance, vdims=['band_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert digital numbers to radiance or reflectance\n",
    "\n",
    "Generalize the example given in the plot above to allow TOA radiance or reflectance for any band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def toa_rad_or_reflect(X, y=None, sample_weight=None,**kw):\n",
    "    rad_or_reflect = kw['rad_or_reflect']\n",
    "    for band in X.data_vars:\n",
    "        num = band.split('_')[-1]\n",
    "        add = getattr(X, '{}_ADD_BAND_{}'.format(rad_or_reflect, num))\n",
    "        mult = getattr(X, '{}_MULT_BAND_{}'.format(rad_or_reflect, num))\n",
    "        band_arr = getattr(X, band)\n",
    "        band_arr.values[:] = band_arr.values * mult + add\n",
    "        if rad_or_reflect == 'REFLECTANCE':\n",
    "            band_arr.values = band_arr.values / np.sin(X.SUN_ELEVATION * (np.pi / 180.))\n",
    "    return (X, y, sample_weight)\n",
    "toa_radiance = partial(toa_rad_or_reflect, rad_or_reflect='RADIANCE')\n",
    "toa_reflectance = partial(toa_rad_or_reflect, rad_or_reflect='REFLECTANCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set `NaN` values for no-data regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_nans(X, y=None, sample_weight=None, **kwargs):\n",
    "    xx = X.copy(deep=True)\n",
    "    for band in xx.data_vars:\n",
    "        band_arr = getattr(xx, band)\n",
    "        band_arr.values = band_arr.values.astype(np.float32)\n",
    "        band_arr.values[band_arr.values <= 1] = np.NaN\n",
    "        band_arr.values[band_arr.values == 2**16] = np.NaN\n",
    "    return (xx, y, sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `elm.pipeline.steps.ModifySample`\n",
    " * Use custom functions in an `elm.pipeline.Pipeline` of transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_nans_step = steps.ModifySample(set_nans)\n",
    "reflectance_step = steps.ModifySample(toa_reflectance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing example\n",
    "\n",
    "Later this notebook using `elm.pipeline.Pipeline` to automate a series of transforms like the one below.  The cell below sets `NaN` values to no-data regions, then converts digital numbers to radiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, _, _ = sampler(download_url)\n",
    "Xnew, _, _ = set_nans_step.fit_transform(X)\n",
    "Xnew, _, _ = reflectance_step.fit_transform(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting reflectance\n",
    "\n",
    "Band 4, Band 3, Band 2 as RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts RGB [width=800 height=600]\n",
    "scale = 0.2\n",
    "bands_432 = ['band_4', 'band_3', 'band_2']\n",
    "hv.RGB(xr.Dataset({band: getattr(Xnew, band) / scale for band in bands_432}), \n",
    "       kdims=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [ width=800 height=600 ]\n",
    "\n",
    "# Xnew.band_2.plot.imshow(levels=levels);\n",
    "# matplotlib.pyplot.title('Band 2 TOA Reflectance');\n",
    "\n",
    "hv.Image(np.where(Xnew.band_2 > 0., Xnew.band_2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized differences between bands\n",
    "\n",
    "Normalized differences between band reflectances may be helpful in feature engineering to differentiate water, urban areas and forests.\n",
    "\n",
    " * NDWI - Normalized Difference Water Index\n",
    " * NDVI - Normalized Difference Vegetation Index\n",
    " * NDSI - Normalized Difference Soil Index\n",
    " * NBR - Normalized Burn Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_diffs = {'ndwi': ('band_4', 'band_5'),\n",
    "                    'ndvi': ('band_5', 'band_4'),\n",
    "                    'ndsi': ('band_2', 'band_6'),\n",
    "                    'nbr':  ('band_4', 'band_7'),\n",
    "                 }\n",
    "normed_diffs_step = steps.NormedBandsDiff(spec=normalized_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = clear_image.download_url.values[0]\n",
    "X, _, _ = sampler(download_url)\n",
    "Xnew, _, _ = set_nans_step.fit_transform(X)\n",
    "Xnew, _, _ = reflectance_step.fit_transform(Xnew)\n",
    "Xnew, _, _ = normed_diffs_step.fit_transform(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Color - Normalized Differences as RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.seterr(invalid='ignore') # the NaN < threshold operation below causes warning\n",
    "def plot_once(bands, scale=1.0, threshold=None):\n",
    "    bands = bands or ['band_4', 'band_3', 'band_2']\n",
    "    subset = xr.Dataset({band: getattr(Xnew, band) / scale for band in bands})\n",
    "    if threshold is not None:\n",
    "        for band in subset.data_vars:\n",
    "            b = getattr(subset, band)\n",
    "            b.values[b < threshold] = threshold\n",
    "    return hv.RGB(subset, kdims=['x', 'y'], vdims=bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts RGB [width=800 height=600]\n",
    "pseudo_1 = plot_once(['ndsi', 'ndvi', 'ndwi'], scale=.9, threshold=0.)\n",
    "pseudo_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Image [width=700 height=600]\n",
    "%%opts Layout [tabs=True tight=True]\n",
    "pl_th = lambda band: hv.Image(getattr(Xnew, band) > 0.)\n",
    "pl = lambda band: hv.Image(getattr(Xnew, band))\n",
    "threshold_plots = pl_th('ndwi') + pl_th('ndsi') + pl_th('ndvi') + pl_th('ndsi')\n",
    "continuous_plots = (pl('ndwi') + pl('ndsi') + pl('ndvi') + pl('ndsi') )\n",
    "bands = pl('band_4') + pl('band_3') + pl('band_2')\n",
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Image [width=700 height=600]\n",
    "%%opts Layout [tabs=True tight=True]\n",
    "continuous_plots + threshold_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=700 height=600]\n",
    "%%opts Layout [tabs=True tight=True]\n",
    "pl('ndsi') * pl('ndvi') + pl('ndwi') * pl('ndvi') + pl('nbr') * pl('ndwi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Difference Soil Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=800 height=600]\n",
    "hv.Image(Xnew.ndsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Difference Water Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=800 height=600]\n",
    "hv.Image(Xnew.ndwi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Burn Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=800 height=600]\n",
    "hv.Image(Xnew.nbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Difference Vegetation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts RGB [width=800 height=600]\n",
    "hv.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting bands for learning\n",
    "The following function could allow hyperparameterization to control which bands and normalized differences become input features to machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NORMALIZED_DIFFS = ('nbr', 'ndsi', 'ndwi', 'ndvi')\n",
    "DEFAULT_BANDS = [band_spec.name for band_spec in BAND_SPECS]\n",
    "def choose_bands(X, y=None, sample_weight=None, **kwargs):\n",
    "    new = {}\n",
    "    bands = kwargs.get('bands', DEFAULT_BANDS)\n",
    "    include_normed_diffs = kwargs.get('include_normed_diffs', True)\n",
    "    for band in bands:\n",
    "        data_arr = getattr(X, band)\n",
    "        new[band] = data_arr\n",
    "    if include_normed_diffs:\n",
    "        for diff in NORMALIZED_DIFFS:\n",
    "            new[diff] = getattr(X, diff)\n",
    "    ks = list(new)\n",
    "    es = ElmStore({k: new[k] for k in ks}, add_canvas=False)\n",
    "    for band in es.data_vars:\n",
    "        es[band].attrs['canvas'] = data_arr.canvas\n",
    "    es.attrs.update(X.attrs)\n",
    "    print('Chose', es.data_vars)\n",
    "    return (es, y, sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `elm.pipeline.steps` for preprocessing\n",
    "The next cell allows a custom function to be used in a `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choose_bands_step = steps.ModifySample(choose_bands,\n",
    "                              bands=DEFAULT_BANDS,\n",
    "                              include_normed_diffs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps flatten rasters to columns and remove no-data pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat = steps.Flatten()\n",
    "drop_na = steps.DropNaRows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps using `sklearn.preprocessing.StandardScaler` to normalize data and `PCA` to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardize = steps.StandardScaler()\n",
    "pca = steps.Transform(PCA(n_components=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  `scikit-learn` estimator\n",
    "\n",
    "The final step in `Pipeline` is a `scikit-learn` estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = MiniBatchKMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a `Pipeline`\n",
    " * List of named steps for hyperparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('set_nans', set_nans_step),\n",
    "                 ('reflect', reflectance_step),\n",
    "                 ('normed_diffs', normed_diffs_step),\n",
    "                 ('choose', choose_bands_step),\n",
    "                 ('flat', flat),\n",
    "                 ('drop_na', drop_na),\n",
    "                 ('standard', standardize),\n",
    "                 ('pca', pca),\n",
    "                 ('est', estimator)],\n",
    "                scoring=kmeans_aic,\n",
    "                scoring_kwargs=dict(score_weights=[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Controlling ensemble initialization\n",
    "\n",
    "Starting with a group of `8` `Pipeline` instances with varying PCA and K-Means parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INIT_ENSEMBLE_SIZE = 8\n",
    "def random_ensemble_member():\n",
    "    n_clusters = np.random.choice(range(7, 12))\n",
    "    n_components = np.random.choice((4, len(DEFAULT_BANDS) - 1))\n",
    "    params = dict(est__n_clusters=n_clusters, pca__n_components=n_components)\n",
    "    # Create a new Pipeline instance with new parameters (unfitted)\n",
    "    new = pipe.new_with_params(**params)\n",
    "    return new\n",
    "\n",
    "def ensemble_init_func(pipe, **kwargs):\n",
    "    '''Initialize Random Pipeline Instances\n",
    "       Vary N of components, N of clusters\n",
    "\n",
    "    Parameters:\n",
    "        pipe: a Pipeline instance\n",
    "        kwargs: Not used here\n",
    "    Returns:\n",
    "        List of Pipeline instances with varying parameters\n",
    "    '''\n",
    "    models = []\n",
    "    for repeat in range(INIT_ENSEMBLE_SIZE):\n",
    "        # Do random choices of parameters with some contraints\n",
    "        models.append(random_ensemble_member())\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Controlling model selection\n",
    "`Pipeline.fit_ensemble` proceeds in generations with `model_selection` called after each generation.  In this example we are scoring with Akaike Information Criterion and modifying the `evolve_n` worst fit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_selection(models, best_idxes=None, **kwargs):\n",
    "    evolve_n = kwargs['evolve_n']\n",
    "    if kwargs['generation'] == kwargs['ngen'] - 1:\n",
    "        return models\n",
    "    if INIT_ENSEMBLE_SIZE > 1:\n",
    "        keep_n = INIT_ENSEMBLE_SIZE - evolve_n\n",
    "        top_idxes = best_idxes[:keep_n]\n",
    "        keep_existing = [(tag, model) for idx, (tag, model) in enumerate(models)\n",
    "                         if idx in top_idxes]\n",
    "        changed_tags = [tag for idx, (tag, model) in enumerate(models)\n",
    "                        if idx not in top_idxes]\n",
    "        random_new = [(tag, random_ensemble_member()) for tag in changed_tags]\n",
    "        return list(keep_existing) + random_new\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `dill` to load a trained model\n",
    "(If it exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_PICKLE = 'landsat.dill'\n",
    "def load_pickled_pipeline():\n",
    "    if os.path.exists(MODEL_PICKLE):\n",
    "        with open(MODEL_PICKLE, 'rb') as f:\n",
    "            fitted = dill.load(f)\n",
    "            return fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `fit_ensemble`\n",
    " * Control number of fitting generations\n",
    " * Control model selection\n",
    " * Control ensemble initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_image_problem(pipe, ngen=3):\n",
    "    fitted = load_pickled_pipeline()\n",
    "    if fitted:\n",
    "        return fitted\n",
    "    evolve_n = INIT_ENSEMBLE_SIZE // 2\n",
    "    ensemble_kwargs = {\n",
    "        'model_selection': model_selection,\n",
    "        'model_selection_kwargs': {'evolve_n': evolve_n,},\n",
    "        'ensemble_init_func': ensemble_init_func,\n",
    "        'models_share_sample': True\n",
    "    }\n",
    "    X, _, _ = sampler(download_url)\n",
    "    print('FIT')\n",
    "    kw = ensemble_kwargs.copy()\n",
    "    kw['ngen'] = ngen\n",
    "    fitted = pipe.fit_ensemble(X=X,\n",
    "                               client=client,\n",
    "                               **kw)\n",
    "    return fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fitted = one_image_problem(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pipeline.predict_many`\n",
    " * Predicts for one or more samples and one or more ensemble members\n",
    " * Uses `distributed` for parallelism\n",
    " * Can return xarray data structure or serialize it\n",
    " * By default, reshapes 1-D predictions to 2-D spatial arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fitted.predict_many(X=X, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `predict_many` returns a list of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the number of predictions is equal to the number of ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds),len(fitted.ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting each ensemble member's prediction\n",
    " * Each prediction is an `ElmStore` (`xarray.Dataset`) with a `predict` 2-D `DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Image [width=700 height=500]\n",
    "%%opts Layout [tabs=True]\n",
    "p = [hv.Image(p.predict) for p in preds[:3]]\n",
    "p[0] + p[1] + p[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps - Hierarchical Modeling\n",
    "\n",
    "Notice in the predictions plotted above, most ensemble members arrived at similar clustering systems, but:\n",
    "\n",
    "* The clusters were named differently in each model (i.e. cluster #1 is not the same in every ensemble member).\n",
    "* The models differed in the water region of the image (Chesapeake Bay) with some models finding two in-water clusters and other models finding one\n",
    "\n",
    "Future development with `elm` will automate the following cells' steps of predicting based on an ensemble of predictions.  The steps are to:\n",
    "\n",
    "* Flatten all predictions\n",
    "* Use a categorical to binary encoder\n",
    "* Predict with K-Means based on the ensemble members' encoded predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def sampler_layer_2(preds):\n",
    "    # This will be simplified in Hierarchical modeling / vote count tasks\n",
    "    predicts = []\n",
    "    for p in preds:\n",
    "        flat, _, _ = steps.Flatten().fit_transform(p.copy(deep=True))\n",
    "        no_na, _, _ = steps.DropNaRows().fit_transform(flat)\n",
    "        predicts.append(no_na.flat.values[:,0])\n",
    "    transformed = OneHotEncoder().fit_transform(np.array(predicts).T).todense()\n",
    "    Xnew = ElmStore({'flat': xr.DataArray(transformed, \n",
    "                                          coords=[('space', no_na.space), \n",
    "                                                  ('band', np.arange(transformed.shape[1]))],\n",
    "                                         dims=('space','band'))},\n",
    "                    attrs=no_na.attrs)\n",
    "    return Xnew\n",
    "X_layer_2 = sampler_layer_2(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a number of clusters to use (randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = np.random.choice([model for tag, model in pipe.ensemble])\n",
    "random_n_clusters = random.get_params()['est__n_clusters']\n",
    "random_n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make a second layer `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_level_2 = MiniBatchKMeans(n_clusters=random_n_clusters)\n",
    "pipe_level_2 = Pipeline([('est', model_level_2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and predict based on ensemble of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_level_2.fit_ensemble(X=X_layer_2, ngen=1, init_ensemble_size=1)\n",
    "preds2 = pipe_level_2.predict_many(X=X_layer_2)\n",
    "len(preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot prediction from hierarchical model\n",
    "\n",
    "This shows some of the Phase II idea of hierarchical models (models on predictions from ensembles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=800 height=600]\n",
    "%%opts Layout [tabs=True]\n",
    "best = preds2[0]\n",
    "hv.Image(best, kdims=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
