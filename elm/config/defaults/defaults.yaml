readers: {
  hdf4-eos: {
     load_array: "elm.readers.hdf4:load_hdf4_array",
     load_meta: "elm.readers.hdf4:load_hdf4_meta"
  },
  dir_of_tifs_reader: {
     load_array: "elm.readers.tif:load_dir_of_tifs_array",
     load_meta: "elm.readers.tif:load_dir_of_tifs_meta"
   },
}

data_sources: {
 NPP_DSRF1KD_L2GD: {
  reader: hdf4-eos,
  file_pattern: "*.hdf",
  sample_from_args_func: "elm.sample_util.samplers:image_selection",
  band_specs: [[long_name, "Band 1 ", band_1],
  [long_name, "Band 2 ", band_2],
  [long_name, "Band 3 ", band_3],
  [long_name, "Band 4 ", band_4],
  [long_name, "Band 5 ", band_5],
  [long_name, "Band 7 ", band_7],
  [long_name, "Band 8 ", band_8],
  [long_name, "Band 10 ", band_10],
  [long_name, "Band 11 ", band_11]],
  sample_args_generator: iter_files_recursively,
  sample_args_generator_kwargs: {
    top_dir: "env:ELM_EXAMPLE_DATA_PATH",
    extension: ".hdf"
  },
  selection_kwargs: {
    data_filter: Null,
    metadata_filter: Null,
    filename_filter: Null,
    geo_filters: {
      include_polys: [],
      exclude_polys: [],
    },
   },
  get_y_func: Null,
  get_y_kwargs: {},
  get_weight_func: Null,
  get_weight_kwargs: {},
  keep_columns: [],
  batch_size: 1440000,

 },
 S3_LANDSAT_L2_TIFS: {
  sample_args_generator: tif_file_gen,
  sample_args_generator_kwargs: {
    top_dir: "env:ELM_EXAMPLE_DATA_PATH"
  },

  selection_kwargs: {},
  reader: dir_of_tifs_reader,
  sample_from_args_func: "elm.sample_util.samplers:image_selection",
  band_specs: [[name, "_B1.TIF", band_1],
  [name, "_B2.TIF", band_2],
  [name, "_B3.TIF", band_3],
  [name, "_B4.TIF", band_4],
  [name, "_B5.TIF", band_5],
  [name, "_B6.TIF", band_6],
  [name, "_B7.TIF", band_7],
  #[name, "_B8.TIF", band_8], # band 8 in panchromatic and at 15 m rather than 30 m
  [name, "_B9.TIF", band_9],
  [name, "_B10.TIF", band_10],
  [name, "_B11.TIF", band_11]],
  get_y_func: Null,
  get_y_kwargs: {},
  get_weight_func: Null,
  get_weight_kwargs: {},
  keep_columns: [],
  batch_size: 1440000,
  },
}
sample_args_generators: {
  tif_file_gen: "elm.readers.local_file_iterators:iter_dirs_of_dirs",
  iter_files_recursively: "elm.readers.local_file_iterators:iter_files_recursively",
}

polys: {

}
resamplers: {

}
aggregations: {

}
masks: {

}
add_features: {
  # an example of an entry here: NPP_DSRF1KD_L2GD_NDVI: "elm.sample_util.add_features:ndvi",
}
feature_selection: {
  select_all: {
    selection: all,
    scoring: chi2,
    scoring_kwargs: {},
    kwargs: {},
    choices: all,
  },
  top_80_percent: {
    selection: "sklearn.feature_selection:SelectPercentile",
    kwargs: {percentile: 80},
    scoring: f_classif,
    choices: all,
  }
}
model_scoring: {
  accuracy_score_cv: {
    scoring: "accuracy_score",
    scoring_agg: "numpy:median",
    greater_is_better: True,
    needs_proba: False,
    needs_threshold: False,
  },
  ensemble_kmeans_scoring: {
    scoring: "elm.model_selection.kmeans:ensemble_kmeans_scoring",
    score_weights: [-1],
  }
}
model_selection: {
  kmeans_model_averaging: {
    kwargs: {
      drop_n: 0,
      init_n: 0,
      evolve_n: 1,
    },
    func: "elm.model_selection.kmeans:kmeans_model_averaging",
  },
  select_top_n: {
    kwargs: {
      top_n: 1,
    },
    func: "elm.model_selection.base:select_top_n_models"
  }
}
ensembles: {
  no_ensemble: {
    init_ensemble_size: 1,  # how many models to initialize at start
    saved_ensemble_size: 1, # how many models to serialize as "best"
    n_generations: 1,       # how many model train/select generations
    batches_per_gen: 1,     # how many partial_fit calls per train/select generation
  },
  small_ensemble: {
    init_ensemble_size: 16,  # how many models to initialize at start
    saved_ensemble_size: 4, # how many models to serialize as "best"
    n_generations: 4,       # how many model train/select generations
    batches_per_gen: 4,     # how many partial_fit calls per train/select generation
  }
}

transform: {
  pca: {
    model_init_class: "sklearn.decomposition:IncrementalPCA",
    model_init_kwargs: {"n_components": 2},
    data_source: NPP_DSRF1KD_L2GD,
    ensemble: no_ensemble,
    model_selection: Null,
    model_scoring: Null

  }
}

sklearn_preprocessing: {
  min_max: {
    method: minmax_scale,
    feature_range: [0, 1],
    axis: 0,
    copy: False,
  },
  standard: {
    method: StandardScaler,
    copy: False,
    with_mean: True,
    with_std: True,
  },
  poly_2nd_interactions_only: {
    method: PolynomialFeatures,
    degree: 2,
    interaction_only: True,
    include_bias: True,
  },
  poly_2nd: {
    method: PolynomialFeatures,
    degree: 2,
    interaction_only: False,
    include_bias: True,
  },
  log: {
    method: FunctionTransformer,
    func: "numpy:log",
    validate: True,
  },
  log10: {
    method: FunctionTransformer,
    func: "numpy:log10",
    validate: True,
  },
  require_positive: {
    method: FunctionTransformer,
    func: "elm.sample_util.encoding_scaling:require_positive",
    func_kwargs: {small_num: 0.0001},
  },
}

sample_pipelines: {
  log10: [
    {sklearn_preprocessing: require_positive},
    {sklearn_preprocessing: log10},
  ],
  standardize_log10: [
    {sample_pipeline: log10},
    {sklearn_preprocessing: standard},
  ],
  standardize_log10_var_top_80: [
    {sample_pipeline: standardize_log10},
    {feature_selection: top_80_percent},
  ],
  standardize_log10_var_top_80_interactions: [
    {sample_pipeline: standardize_log10_var_top_80},
    {sklearn_preprocessing: poly_2nd_interactions_only},
  ]
}

train: {
  kmeans: {
    model_init_class: "sklearn.cluster:MiniBatchKMeans",
    # TODO Deprecate code dealing with: "post_fit_func":
    fit_kwargs: {},
    model_init_kwargs: {
      compute_labels: True
    },
    ensemble: no_ensemble,
    output_tag: kmeans,
    data_source: NPP_DSRF1KD_L2GD,
    keep_columns: [],
    model_scoring: ensemble_kmeans_scoring,
    model_selection: kmeans_model_averaging,
    param_grid: {n_clusters: [3,4,5,6,7,8]}
  }
}

predict: {
  kmeans: {
    data_source: NPP_DSRF1KD_L2GD,
    sample_args_generator: iter_files_recursively,
    sample_args_generator_kwargs: {
      top_dir: 'env:ELM_EXAMPLE_DATA_PATH',
      extension: '.hdf'
    }
  }
}
change_detection: {
  time_series: []
}
pipeline:
  - {transform: pca,
     method: partial_fit,
     sample_pipeline: [
      {feature_selection: select_all},
    ]}
  - {train: kmeans,
     method: partial_fit,
     sample_pipeline: [
      {feature_selection: select_all},
      {transform: pca, method: transform},
    ]}
  - {predict: kmeans,
     sample_pipeline: [
      {feature_selection: select_all},
      {transform: pca, method: transform},
      ]
    }


# Config options that can be overriden by environment variables:
DASK_THREADS: Null # os.cpu_count() if not given
DASK_PROCESSES: Null  # os.cpu_count() if not given
DASK_EXECUTOR: SERIAL
DASK_SCHEDULER: Null
LADSWEB_LOCAL_CACHE: Null
